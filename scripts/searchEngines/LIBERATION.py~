# -*- coding: utf-8 -*-
#import urllib2, html5lib
import urllib2, lxml.html, re






###_________________________________________________________________________________####


def produceAddressURL(currentQuery):
	'''
		input (str="name dd-mm-yyyy-dd-mm-yyyy numberOfPage Key")
		output (list=list of article URL)
		
		at first generates the url for the searche engine using typical patterns
		then realizes a query on Liberation.fr and return the output html5 page to a list
		finally parses the html page to extract links to liberation articles
		
	'''

	item = currentQuery.rstrip().split(' ')
	name      = item[0] # pattern
	date      = item[1].split('-') # date
	nbP       = int(item[2]) # nb of pages
	speakerID = item[3] # keyName
	
	if len(date) != 6:
		print 'check date ' + date + '\n'
		exit();
	
	urlList = list()
	
	for idPage in range(1, nbP + 1):
		urlList.append('http://www.liberation.fr/recherche/?q=' + name + '&period=custom' + '&period_start_day=' + str(int(date[0])-1) + '&period_start_month=' + date[1] + '&period_start_year=' + date[2] + '&period_end_day=' + date[3] + '&period_end_month=' + date[4] + '&period_end_year=' + date[5] + '&editorial_source=' + '&paper_channel=' + '&sort=-publication_date_time' + '&page=' + str(idPage) + '&period=custom')



	# ___ pour le test ___ #
	urlList = ['http://www.liberation.fr/recherche/?q=sarkozy&period=custom&period_start_day=1&period_start_month=4&period_start_year=2012&period_end_day=2&period_end_month=4&period_end_year=2012&editorial_source=&paper_channel=&sort=-publication_date_time']



	allReturnedURL = list()

	#print urlList
	for url in urlList :
		f = urllib2.urlopen(url)
		data = f.read()
		f.close()
		doc = lxml.html.document_fromstring(data)
		#text2 = doc.xpath('//div[@id="body-content"]/div[@class="wrapper line"]/div[@class="grid-2-1 main-content line"]/div[@class="mod"]/section[@class="timeline"]/div[@class="day"]/ul/li/*/h2/a/@href')
		
		for returnedUrl in doc.xpath('////section[@class="timeline"]/div[@class="day"]/ul/li/*/h2/a/@href') :
			if not re.match('^http' , returnedUrl ):
				allReturnedURL.append('http://www.liberation.fr/'+returnedUrl)
	
	# if verbose 1
	print( currentQuery + ": " + str(len(allReturnedURL)) + ' documents trouv√©s') 
	# if verbose 2
	for i in allReturnedURL :
		print i
		

	return allReturnedURL	
		
		
###______________________________________________________________________________####

def cleanResultFile(url):
	f = urllib2.urlopen(url)
	data = f.read()
	f.close()

	doc = lxml.html.document_fromstring(data)

	text = doc.xpath('//*/div[@class="article-body mod"]/div/*/text()')
	return text

